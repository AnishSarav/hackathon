{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32021d49",
   "metadata": {},
   "source": [
    "# ðŸ§  EEG Brain State Classifier â€” Hackathon Demo\n",
    "\n",
    "## Can a computer tell if you're relaxed or stressed... just from your brainwaves?\n",
    "\n",
    "**What we built:** A machine learning system that:\n",
    "1. Reads brainwave data from an OpenBCI EEG headset (8 electrodes on your head)\n",
    "2. Figures out if you are **Relaxed** or **Stressed / Focused**\n",
    "3. When you're stressed â†’ it **automatically plays soothing music** to help you relax!\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ—ºï¸ Notebook Roadmap (What We'll Do)\n",
    "\n",
    "| Step | What Happens | Why It Matters |\n",
    "|------|-------------|----------------|\n",
    "| **Part A** | Install tools & load data | Get our brainwave files ready |\n",
    "| **Part B** | Build a SIMPLE model (the \"bad\" one) | See why naive approaches fail |\n",
    "| **Part C** | Fix the problems & build a BETTER model | Learn how real data science works |\n",
    "| **Part D** | Simulated live demo with music | Show it working on a recording |\n",
    "| **Part E** | REAL live demo with headset | The showstopper! |\n",
    "| **Part F** | How to answer judge questions | Be ready for anything |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª The Science Behind It\n",
    "\n",
    "Your brain produces tiny electrical signals called **brainwaves**. Different mental states produce different patterns:\n",
    "\n",
    "```\n",
    "  ðŸ˜´ Delta waves (1-4 Hz)   â†’ Deep sleep\n",
    "  ðŸ§˜ Theta waves (4-8 Hz)   â†’ Meditation, daydreaming\n",
    "  ðŸ˜Œ Alpha waves (8-13 Hz)  â†’ Relaxed, calm, eyes closed\n",
    "  ðŸ¤” Beta waves  (13-30 Hz) â†’ Active thinking, problem-solving\n",
    "  ðŸ§  Gamma waves (30-45 Hz) â†’ Intense focus, learning\n",
    "```\n",
    "\n",
    "**Key insight:** When you're relaxed, your brain produces MORE alpha waves. When you're stressed or thinking hard, beta waves go up and alpha goes down.\n",
    "\n",
    "We measure the STRENGTH (power) of each wave type and let a machine learning model learn the pattern!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2949ea8",
   "metadata": {},
   "source": [
    "---\n",
    "#  PART A: Setup & Load Data\n",
    "\n",
    "## Step A1: Install the tools we need\n",
    "\n",
    "Think of these like apps on your phone â€” each one does something special:\n",
    "- **pandas** = reads data files (like Excel for Python)\n",
    "- **numpy** = does math on numbers\n",
    "- **scipy** = signal processing (analyzing wave patterns)\n",
    "- **scikit-learn** = machine learning (the \"brain\" of our classifier)\n",
    "- **matplotlib** = draws charts and graphs\n",
    "- **pygame** = plays music\n",
    "- **brainflow** = talks to the OpenBCI headset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282130",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.conda (Python 3.12.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p /Users/sriramsridhar/Library/Application Support/Claude/local-agent-mode-sessions/103367e3-afe5-4f8e-b911-39e36931ebf6/7565d005-b309-44ec-90e4-f29d0e58efae/local_e76b4ae2-6fc6-4b57-9a8e-09887737e9f3/outputs/.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Run this cell to install everything (takes ~30 seconds)\n",
    "!pip install pandas numpy scipy scikit-learn matplotlib pygame brainflow joblib -q\n",
    "print('All tools installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15edb0cd",
   "metadata": {},
   "source": [
    "## Step A2: Import the tools into our notebook\n",
    "This is like opening the apps we just installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import joblib\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf7139",
   "metadata": {},
   "source": [
    "## Step A3: Define the brainwave frequency bands\n",
    "\n",
    "This is where we tell the computer what frequency ranges correspond to which brain waves.\n",
    "\n",
    "**Analogy:** Imagine a radio â€” you tune to different frequencies to hear different stations. Our brain has \"stations\" too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brainwave frequency bands (in Hertz = cycles per second)\n",
    "BANDS = {\n",
    "    'delta': (1, 4),      # Very slow waves - deep sleep\n",
    "    'theta': (4, 8),      # Slow waves - meditation, drowsiness\n",
    "    'alpha': (8, 13),     # Medium waves - RELAXED (the key one!)\n",
    "    'beta':  (13, 30),    # Fast waves - THINKING HARD / STRESSED\n",
    "    'gamma': (30, 45)     # Very fast waves - intense focus\n",
    "}\n",
    "\n",
    "SAMPLING_RATE = 250   # Our headset records 250 data points per second\n",
    "NUM_CHANNELS = 8      # We have 8 electrodes on the head\n",
    "\n",
    "print(\"Brainwave bands defined:\")\n",
    "for name, (low, high) in BANDS.items():\n",
    "    bar = \"#\" * (high - low)\n",
    "    print(f\"   {name:6s} : {low:2d} - {high:2d} Hz  {bar}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f973f",
   "metadata": {},
   "source": [
    "## Step A4: Connect to Google Drive and load our EEG data files\n",
    "\n",
    "We recorded brainwave data using the OpenBCI headset while the subject was in different mental states. Each file is named like:\n",
    "- `relaxation_01.csv` - person was relaxing\n",
    "- `focus_02.csv` - person was doing math problems\n",
    "- `negative_03.csv` - person was watching stressful videos\n",
    "- `meditation_01.csv` - person was meditating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ae848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Google Drive (where our data lives)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    DATA_FOLDER = '/content/drive/MyDrive/eeg_data'\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Drive connected!\")\n",
    "except ImportError:\n",
    "    DATA_FOLDER = './eeg_data'\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally - using ./eeg_data folder\")\n",
    "\n",
    "# Show all the files we have\n",
    "print(f\"\\nData folder: {DATA_FOLDER}\")\n",
    "print(f\"\\nFiles we found:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "csv_files = []\n",
    "for f in sorted(os.listdir(DATA_FOLDER)):\n",
    "    if f.endswith('.csv') and 'test' not in f.lower():\n",
    "        csv_files.append(f)\n",
    "        raw_label = f.split('_')[0]\n",
    "        print(f\"   {f:35s}  (label: '{raw_label}')\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nTotal training files: {len(csv_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7ac36a",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ…±ï¸ PART B: The \"Naive\" Model (Low Accuracy â€” Let's See Why!)\n",
    "\n",
    "Before we build the good model, let's see what happens when we just throw the data at machine learning without thinking carefully. **This is an important lesson: garbage in = garbage out!**\n",
    "\n",
    "### What we'll do:\n",
    "1. Load each file and extract ONE set of features per file\n",
    "2. Use the raw filename as the label\n",
    "3. Train a Random Forest and see how badly it does\n",
    "\n",
    "### What is Power Spectral Density (PSD)?\n",
    "Imagine you have a song playing. PSD is like an equalizer display that shows you which frequencies are present and how loud each one is. For brainwaves, PSD tells us how much power is in each frequency band. More alpha power = more relaxed!\n",
    "\n",
    "The **Welch method** calculates PSD by:\n",
    "1. Split the signal into overlapping chunks\n",
    "2. Calculate the frequency content of each chunk (using Fourier Transform)\n",
    "3. Average them together (this reduces noise and gives a cleaner picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c275866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE (NAIVE) FEATURE EXTRACTION\n",
    "# One feature vector per entire file\n",
    "\n",
    "def extract_features_simple(filename):\n",
    "    # Get label from filename: \"relaxation_01.csv\" -> \"relaxation\"\n",
    "    basename = os.path.basename(filename)\n",
    "    label = basename.split('_')[0]\n",
    "\n",
    "    # Read the CSV file (tab-separated, no header row)\n",
    "    df = pd.read_csv(filename, header=None, sep='\\t')\n",
    "\n",
    "    if df.shape[1] < 9:\n",
    "        print(f\"   Warning: {basename} has too few columns!\")\n",
    "        return [], label\n",
    "\n",
    "    # Get 8 EEG channels (columns 1-8), transpose so each ROW is one channel\n",
    "    eeg_data = df.iloc[:, 1:9].values.T   # Shape: (8, num_samples)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for channel_data in eeg_data:\n",
    "        channel_data = channel_data[~np.isnan(channel_data)]  # Remove NaN values\n",
    "\n",
    "        if len(channel_data) < SAMPLING_RATE:\n",
    "            features.extend([0.2] * 5)\n",
    "            continue\n",
    "\n",
    "        # THE KEY STEP: Calculate Power Spectral Density using Welch method\n",
    "        frequencies, power = welch(channel_data, fs=SAMPLING_RATE,\n",
    "                                    nperseg=min(2048, len(channel_data)))\n",
    "\n",
    "        # Calculate power in each brainwave band\n",
    "        band_powers = []\n",
    "        for band_name, (low, high) in BANDS.items():\n",
    "            in_band = (frequencies >= low) & (frequencies <= high)\n",
    "            band_power = np.trapezoid(power[in_band], frequencies[in_band]) if np.any(in_band) else 0.0\n",
    "            band_powers.append(band_power)\n",
    "\n",
    "        # Convert to RELATIVE power (percentages adding to 100%)\n",
    "        total_power = sum(band_powers)\n",
    "        if total_power == 0:\n",
    "            total_power = 1.0\n",
    "        relative_powers = [p / total_power for p in band_powers]\n",
    "        features.extend(relative_powers)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "print(\"Simple feature extraction function defined!\")\n",
    "print(f\"   Output: {NUM_CHANNELS * len(BANDS)} features per file (8 channels x 5 bands)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f9221",
   "metadata": {},
   "source": [
    "## Step B2: Load all files and train the naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading all training files (naive approach)...\\n\")\n",
    "\n",
    "naive_features = []\n",
    "naive_labels = []\n",
    "\n",
    "for filename in sorted(os.listdir(DATA_FOLDER)):\n",
    "    if filename.endswith('.csv') and 'test' not in filename.lower():\n",
    "        filepath = os.path.join(DATA_FOLDER, filename)\n",
    "        features, label = extract_features_simple(filepath)\n",
    "        if features:\n",
    "            naive_features.append(features)\n",
    "            naive_labels.append(label)\n",
    "            print(f\"   {filename:35s} -> label: '{label}'\")\n",
    "\n",
    "unique_labels = sorted(set(naive_labels))\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NAIVE DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Total samples:    {len(naive_features)}\")\n",
    "print(f\"   Unique labels:    {unique_labels}\")\n",
    "print(f\"   Number of classes: {len(unique_labels)}\")\n",
    "print()\n",
    "for label in unique_labels:\n",
    "    count = naive_labels.count(label)\n",
    "    print(f\"   '{label}': {count} samples\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PROBLEMS WE CAN ALREADY SEE:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   1. 'relaxing' and 'relaxation' are DIFFERENT classes!\")\n",
    "print(f\"      (But they mean the same thing!)\")\n",
    "print(f\"   2. We have {len(unique_labels)} classes but only {len(naive_features)} samples total\")\n",
    "print(f\"      (That's only ~{len(naive_features)//max(len(unique_labels),1)} samples per class)\")\n",
    "print(f\"   3. Each file gives us only ONE training sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE NAIVE MODEL\n",
    "\n",
    "naive_label_to_num = {label: i for i, label in enumerate(unique_labels)}\n",
    "naive_num_to_label = {i: label for label, i in naive_label_to_num.items()}\n",
    "y_naive = np.array([naive_label_to_num[l] for l in naive_labels])\n",
    "X_naive = np.array(naive_features)\n",
    "\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(\n",
    "    X_naive, y_naive, test_size=0.3, random_state=42, stratify=y_naive)\n",
    "\n",
    "naive_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "naive_model.fit(X_train_n, y_train_n)\n",
    "\n",
    "y_pred_n = naive_model.predict(X_test_n)\n",
    "naive_accuracy = accuracy_score(y_test_n, y_pred_n)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"NAIVE MODEL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n   Accuracy: {naive_accuracy:.0%}\")\n",
    "if naive_accuracy < 0.5:\n",
    "    print(f\"\\n   That's WORSE than flipping a coin!\")\n",
    "    print(f\"   (Random guessing = {1/len(unique_labels):.0%})\")\n",
    "print(f\"\\n   Don't worry - we'll fix this in Part C!\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_naive = confusion_matrix(y_test_n, y_pred_n)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm_naive, cmap='Reds')\n",
    "ax.set_title(f'Naive Model Confusion Matrix (Accuracy: {naive_accuracy:.0%})', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(range(len(unique_labels)))\n",
    "ax.set_yticks(range(len(unique_labels)))\n",
    "ax.set_xticklabels(unique_labels, rotation=45, ha='right')\n",
    "ax.set_yticklabels(unique_labels)\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "for i in range(len(unique_labels)):\n",
    "    for j in range(len(unique_labels)):\n",
    "        ax.text(j, i, str(cm_naive[i, j]), ha='center', va='center',\n",
    "                fontsize=16, fontweight='bold',\n",
    "                color='white' if cm_naive[i, j] > cm_naive.max()/2 else 'black')\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe model is confused because:\")\n",
    "print(\"   * 'relaxing' and 'relaxation' SHOULD be the same class\")\n",
    "print(\"   * Too many classes with too few samples per class\")\n",
    "print(\"   * Each file produces only 1 training sample\")\n",
    "print(\"\\nLet's fix ALL of these in Part C!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79076ab1",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ…² PART C: Building the GOOD Model\n",
    "\n",
    "Now we fix the three problems:\n",
    "\n",
    "### Fix 1: Merge similar labels into just 2 classes (Binary classification)\n",
    "- **\"relaxed\"** = relaxation + relaxing + meditation (calm brain states)\n",
    "- **\"not_relaxed\"** = focus + negative + deepthinking (active/stressed brain states)\n",
    "\n",
    "### Fix 2: Sliding window augmentation gives us 50x more training data!\n",
    "Instead of 1 sample per file, we slide a 4-second window across each 60-second recording:\n",
    "```\n",
    "File: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (60 seconds)\n",
    "Window 1:  [â–ˆâ–ˆâ–ˆâ–ˆ]                    -> 1 sample\n",
    "Window 2:   [â–ˆâ–ˆâ–ˆâ–ˆ]                   -> 1 sample\n",
    "Window 3:    [â–ˆâ–ˆâ–ˆâ–ˆ]                  -> 1 sample\n",
    "...\n",
    "Window 56:                    [â–ˆâ–ˆâ–ˆâ–ˆ] -> 1 sample\n",
    "Result: 1 file -> ~56 training samples!\n",
    "```\n",
    "\n",
    "### Fix 3: Extra \"smart\" features\n",
    "We add **alpha/beta ratio** â€” the single best indicator of relaxation:\n",
    "- High alpha / low beta -> relaxed\n",
    "- Low alpha / high beta -> stressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16310104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX 1: LABEL MAPPING\n",
    "# Map messy filenames to clean binary labels\n",
    "\n",
    "LABEL_MAP = {\n",
    "    'relaxing':     'relaxed',\n",
    "    'relaxation':   'relaxed',\n",
    "    'meditation':   'relaxed',\n",
    "    'negative':     'not_relaxed',\n",
    "    'focus':        'not_relaxed',\n",
    "    'deepthinking': 'not_relaxed',\n",
    "    'stressed':     'not_relaxed',\n",
    "}\n",
    "\n",
    "CLASS_NAMES = ['relaxed', 'not_relaxed']\n",
    "\n",
    "print(\"Label mapping defined:\")\n",
    "for raw, mapped in sorted(LABEL_MAP.items()):\n",
    "    emoji = \"(calm)\" if mapped == \"relaxed\" else \"(active)\"\n",
    "    print(f\"   '{raw}' -> '{mapped}' {emoji}\")\n",
    "print(f\"\\n   From {len(set(LABEL_MAP.keys()))} messy labels -> {len(CLASS_NAMES)} clean classes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX 2 & 3: IMPROVED FEATURE EXTRACTION WITH AUGMENTATION\n",
    "\n",
    "def extract_band_powers_one_channel(signal_segment):\n",
    "    # For ONE channel: calculate relative power in each band\n",
    "    # Returns 5 numbers that add up to ~1.0 (100%)\n",
    "    if len(signal_segment) < SAMPLING_RATE:\n",
    "        return [0.2] * len(BANDS)\n",
    "\n",
    "    nperseg = min(2 * SAMPLING_RATE, len(signal_segment))\n",
    "    frequencies, power = welch(signal_segment, fs=SAMPLING_RATE, nperseg=nperseg)\n",
    "\n",
    "    band_powers = []\n",
    "    for low, high in BANDS.values():\n",
    "        mask = (frequencies >= low) & (frequencies <= high)\n",
    "        bp = np.trapezoid(power[mask], frequencies[mask]) if np.any(mask) else 0.0\n",
    "        band_powers.append(bp)\n",
    "\n",
    "    total = sum(band_powers)\n",
    "    if total == 0:\n",
    "        return [0.2] * len(BANDS)\n",
    "    return [p / total for p in band_powers]\n",
    "\n",
    "\n",
    "def extract_features_improved(eeg_window):\n",
    "    # Extract features from an 8-channel EEG window\n",
    "    # Returns 44 features: 40 band powers + 4 ratio features\n",
    "    features = []\n",
    "    alpha_list = []\n",
    "    beta_list = []\n",
    "    theta_list = []\n",
    "\n",
    "    for ch in range(eeg_window.shape[0]):\n",
    "        channel_data = eeg_window[ch]\n",
    "        channel_data = channel_data[~np.isnan(channel_data)]\n",
    "        bp = extract_band_powers_one_channel(channel_data)\n",
    "        features.extend(bp)\n",
    "\n",
    "        # bands order: delta(0), theta(1), alpha(2), beta(3), gamma(4)\n",
    "        alpha_list.append(bp[2])\n",
    "        beta_list.append(bp[3])\n",
    "        theta_list.append(bp[1])\n",
    "\n",
    "    # FIX 3: SMART RATIO FEATURES (our secret weapon!)\n",
    "    avg_alpha = np.mean(alpha_list)\n",
    "    avg_beta = np.mean(beta_list) + 1e-10    # tiny number to prevent divide-by-zero\n",
    "    avg_theta = np.mean(theta_list)\n",
    "\n",
    "    features.append(avg_alpha / avg_beta)     # Alpha/Beta ratio = KEY relaxation indicator\n",
    "    features.append(avg_theta / avg_beta)     # Theta/Beta ratio = meditation indicator\n",
    "    features.append(avg_alpha)                # Average alpha power\n",
    "    features.append(avg_beta)                 # Average beta power\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_file_with_augmentation(filepath, label, window_sec=4, step_sec=1):\n",
    "    # Load one CSV and extract MANY training samples using sliding windows\n",
    "    # A 60-second file -> approximately 56 samples!\n",
    "    df = pd.read_csv(filepath, header=None, sep='\\t')\n",
    "    if df.shape[1] < 9:\n",
    "        return [], []\n",
    "\n",
    "    eeg_data = df.iloc[:, 1:9].values.T\n",
    "    total_samples = eeg_data.shape[1]\n",
    "    window_samples = int(window_sec * SAMPLING_RATE)\n",
    "    step_samples = int(step_sec * SAMPLING_RATE)\n",
    "\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    start = 0\n",
    "    while start + window_samples <= total_samples:\n",
    "        window = eeg_data[:, start:start + window_samples]\n",
    "        feats = extract_features_improved(window)\n",
    "        features_list.append(feats)\n",
    "        labels_list.append(label)\n",
    "        start += step_samples\n",
    "\n",
    "    return features_list, labels_list\n",
    "\n",
    "print(\"Improved feature extraction functions defined!\")\n",
    "print(f\"   Features per sample: {NUM_CHANNELS * len(BANDS)} band powers + 4 ratios = {NUM_CHANNELS * len(BANDS) + 4} total\")\n",
    "print(f\"   Window size: 4 seconds ({4 * SAMPLING_RATE} data points)\")\n",
    "print(f\"   Step size: 1 second (lots of overlap = lots of training data!)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f452f",
   "metadata": {},
   "source": [
    "## Step C3: Load all data with the improved approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and augmenting all training files...\\n\")\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for filename in sorted(os.listdir(DATA_FOLDER)):\n",
    "    if not filename.endswith('.csv') or 'test' in filename.lower():\n",
    "        continue\n",
    "\n",
    "    raw_label = filename.split('_')[0]\n",
    "    mapped_label = LABEL_MAP.get(raw_label)\n",
    "\n",
    "    if mapped_label is None:\n",
    "        print(f\"   Unknown label '{raw_label}' in {filename} - skipping!\")\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(DATA_FOLDER, filename)\n",
    "    feats, labels = load_file_with_augmentation(filepath, mapped_label)\n",
    "    all_features.extend(feats)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "    tag = \"(calm)\" if mapped_label == \"relaxed\" else \"(active)\"\n",
    "    print(f\"   {filename:35s} -> {mapped_label:12s} ({len(feats)} windows) {tag}\")\n",
    "\n",
    "X = np.array(all_features)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "label_to_num = {'relaxed': 0, 'not_relaxed': 1}\n",
    "num_to_label = {0: 'relaxed', 1: 'not_relaxed'}\n",
    "y_encoded = np.array([label_to_num[l] for l in y])\n",
    "\n",
    "relaxed_count = sum(1 for l in y if l == 'relaxed')\n",
    "stressed_count = sum(1 for l in y if l == 'not_relaxed')\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"IMPROVED DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Total samples:     {len(X):,}\")\n",
    "print(f\"   Feature dimensions: {X.shape[1]}\")\n",
    "print(f\"   Relaxed:         {relaxed_count:,} samples ({relaxed_count/len(y)*100:.1f}%)\")\n",
    "print(f\"   Not Relaxed:     {stressed_count:,} samples ({stressed_count/len(y)*100:.1f}%)\")\n",
    "print(f\"\\n   That's {len(X)//max(len(naive_features),1)}x MORE training data than the naive approach!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a52ec",
   "metadata": {},
   "source": [
    "## Step C4: Train the improved model\n",
    "\n",
    "We use a **Random Forest** with 200 decision trees and **cross-validation** (like taking 5 different practice tests to make sure our model isn't just memorizing).\n",
    "\n",
    "**What is a Random Forest?**\n",
    "Imagine asking 200 different \"experts\" (decision trees) to vote on whether the brain is relaxed or not. Each expert looks at slightly different data. The final answer is whatever the MAJORITY votes for â€” wisdom of the crowd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE IMPROVED MODEL\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples\")\n",
    "print(f\"Test set:     {len(X_test):,} samples\\n\")\n",
    "\n",
    "# Model pipeline: normalize features, then Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=15, min_samples_leaf=3,\n",
    "        class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "print(\"Running 5-fold cross-validation...\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y_encoded, cv=cv, scoring='accuracy')\n",
    "print(f\"   Fold scores: {[f'{s:.1%}' for s in cv_scores]}\")\n",
    "print(f\"   Average:     {cv_scores.mean():.1%} (+/- {cv_scores.std():.1%})\")\n",
    "\n",
    "# Train final model\n",
    "print(f\"\\nTraining final model on {len(X_train):,} samples...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"IMPROVED MODEL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.0%}\")\n",
    "print(f\"   (Naive model was: {naive_accuracy:.0%})\")\n",
    "print(f\"   Improvement: +{test_accuracy - naive_accuracy:.0%}!\")\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, target_names=CLASS_NAMES))\n",
    "\n",
    "# Save model\n",
    "MODEL_PATH = os.path.join(DATA_FOLDER, 'brain_classifier_hackathon.pkl')\n",
    "joblib.dump({\n",
    "    'pipeline': pipeline, 'num_to_label': num_to_label,\n",
    "    'label_to_num': label_to_num, 'class_names': CLASS_NAMES,\n",
    "    'bands': BANDS, 'sampling_rate': SAMPLING_RATE, 'num_channels': NUM_CHANNELS,\n",
    "}, MODEL_PATH)\n",
    "print(f\"Model saved to: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26dbbe0",
   "metadata": {},
   "source": [
    "## Step C5: Visualize â€” Before vs After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cca5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Bar chart comparison\n",
    "ax0 = axes[0]\n",
    "models = ['Naive Model\\n(Before)', 'Improved Model\\n(After)']\n",
    "accuracies = [naive_accuracy * 100, test_accuracy * 100]\n",
    "colors = ['#e74c3c', '#2ecc71']\n",
    "bars = ax0.bar(models, accuracies, color=colors, width=0.5, edgecolor='black')\n",
    "ax0.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax0.set_title('Accuracy: Before vs After', fontsize=14, fontweight='bold')\n",
    "ax0.set_ylim(0, 105)\n",
    "ax0.axhline(y=50, color='gray', linestyle='--', alpha=0.5, label='Random guessing')\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax0.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "             f'{acc:.0f}%', ha='center', fontsize=16, fontweight='bold')\n",
    "ax0.legend(fontsize=10)\n",
    "\n",
    "# Improved confusion matrix\n",
    "ax1 = axes[1]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "im = ax1.imshow(cm, cmap='Greens')\n",
    "ax1.set_title('Improved Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks([0, 1])\n",
    "ax1.set_yticks([0, 1])\n",
    "ax1.set_xticklabels(['Relaxed', 'Not Relaxed'], fontsize=11)\n",
    "ax1.set_yticklabels(['Relaxed', 'Not Relaxed'], fontsize=11)\n",
    "ax1.set_xlabel('Predicted', fontsize=12)\n",
    "ax1.set_ylabel('Actual', fontsize=12)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax1.text(j, i, str(cm[i, j]), ha='center', va='center',\n",
    "                fontsize=20, fontweight='bold',\n",
    "                color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "plt.colorbar(im, ax=ax1)\n",
    "\n",
    "# Feature importance\n",
    "ax2 = axes[2]\n",
    "clf = pipeline.named_steps['clf']\n",
    "importances = clf.feature_importances_\n",
    "feat_names = []\n",
    "for ch in range(NUM_CHANNELS):\n",
    "    for band in BANDS.keys():\n",
    "        feat_names.append(f\"Ch{ch+1}_{band}\")\n",
    "feat_names.extend(['alpha/beta', 'theta/beta', 'mean_alpha', 'mean_beta'])\n",
    "top_k = 15\n",
    "top_idx = np.argsort(importances)[-top_k:]\n",
    "colors_feat = ['#e74c3c' if 'alpha' in feat_names[i] or 'beta' in feat_names[i] else '#3498db' for i in top_idx]\n",
    "ax2.barh(range(top_k), importances[top_idx], color=colors_feat)\n",
    "ax2.set_yticks(range(top_k))\n",
    "ax2.set_yticklabels([feat_names[i] for i in top_idx], fontsize=9)\n",
    "ax2.set_title('Top 15 Most Important Features', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Importance Score', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(DATA_FOLDER, 'model_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Key takeaway: Alpha and Beta features are the most important!\")\n",
    "print(\"   Alpha waves go UP when relaxed\")\n",
    "print(\"   Beta waves go UP when stressed/thinking\")\n",
    "print(\"   The alpha/beta RATIO is the #1 indicator!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791daa63",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ…³ PART D: Simulated Live Demo (with Soothing Music!)\n",
    "\n",
    "Now the fun part! We take a **test recording** (a file the model has NEVER seen) and simulate real-time classification.\n",
    "\n",
    "When the person is NOT relaxed -> **soothing music plays automatically!**\n",
    "\n",
    "### About the soothing music\n",
    "We generate calming ambient tones using healing frequencies (174 Hz, 285 Hz, 396 Hz) with a gentle breathing rhythm. You can also use any .wav/.mp3 from:\n",
    "- [Pixabay Free Relaxing Music](https://pixabay.com/music/search/relax/) (no attribution required)\n",
    "- [Mixkit Free Ambient Music](https://mixkit.co/free-stock-music/ambient/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e678d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE SOOTHING MUSIC\n",
    "import wave\n",
    "\n",
    "def create_soothing_wav(filename, duration_sec=90, sample_rate=44100):\n",
    "    t = np.linspace(0, duration_sec, int(sample_rate * duration_sec), endpoint=False)\n",
    "\n",
    "    # Layer calming frequencies\n",
    "    signal = np.zeros_like(t)\n",
    "    signal += 0.15 * np.sin(2 * np.pi * 174 * t)    # Calming tone\n",
    "    signal += 0.12 * np.sin(2 * np.pi * 285 * t)    # Healing tone\n",
    "    signal += 0.08 * np.sin(2 * np.pi * 396 * t)    # Releasing tone\n",
    "    signal += 0.06 * np.sin(2 * np.pi * 176 * t)    # Gentle 2Hz beating\n",
    "    signal += 0.04 * np.sin(2 * np.pi * 528 * t)    # Soft shimmer\n",
    "\n",
    "    # Fade in/out\n",
    "    fade = int(3 * sample_rate)\n",
    "    signal[:fade] *= np.linspace(0, 1, fade)\n",
    "    signal[-fade:] *= np.linspace(1, 0, fade)\n",
    "\n",
    "    # Breathing effect\n",
    "    breathing = 0.8 + 0.2 * np.sin(2 * np.pi * 0.15 * t)\n",
    "    signal *= breathing\n",
    "\n",
    "    signal = signal / np.max(np.abs(signal)) * 0.7\n",
    "    signal_int = (signal * 32767).astype(np.int16)\n",
    "\n",
    "    with wave.open(filename, 'w') as f:\n",
    "        f.setnchannels(1)\n",
    "        f.setsampwidth(2)\n",
    "        f.setframerate(sample_rate)\n",
    "        f.writeframes(signal_int.tobytes())\n",
    "    print(f\"Created: {filename} ({duration_sec}s of calming ambient sound)\")\n",
    "\n",
    "MUSIC_FILE = os.path.join(DATA_FOLDER, 'soothing_music.wav')\n",
    "create_soothing_wav(MUSIC_FILE)\n",
    "\n",
    "# Set up audio playback\n",
    "music_available = False\n",
    "try:\n",
    "    import pygame\n",
    "    pygame.mixer.init()\n",
    "    if os.path.exists(MUSIC_FILE):\n",
    "        pygame.mixer.music.load(MUSIC_FILE)\n",
    "        music_available = True\n",
    "        print(\"Audio playback ready!\")\n",
    "    else:\n",
    "        print(\"Music file not found (visual demo only)\")\n",
    "except Exception as e:\n",
    "    print(f\"Audio not available: {e}\")\n",
    "    print(\"   (Normal in Colab - music works on your laptop!)\")\n",
    "\n",
    "def play_soothing_music():\n",
    "    if music_available and not pygame.mixer.music.get_busy():\n",
    "        pygame.mixer.music.play(-1)\n",
    "\n",
    "def stop_soothing_music():\n",
    "    if music_available and pygame.mixer.music.get_busy():\n",
    "        pygame.mixer.music.fadeout(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e29e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATED LIVE DEMO FUNCTION\n",
    "\n",
    "def simulated_live_demo(filename, window_sec=4, step_sec=2):\n",
    "    saved = joblib.load(MODEL_PATH)\n",
    "    demo_pipeline = saved['pipeline']\n",
    "    demo_num_to_label = saved['num_to_label']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SIMULATED LIVE BRAIN STATE CLASSIFICATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  File:     {os.path.basename(filename)}\")\n",
    "    print(f\"  Window:   {window_sec} seconds\")\n",
    "    print(f\"  Update:   every {step_sec} seconds\")\n",
    "    print(f\"  Music:    {'Ready' if music_available else 'Visual only'}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    df = pd.read_csv(filename, header=None, sep='\\t')\n",
    "    if df.shape[1] < 9:\n",
    "        print(\"File has too few columns!\")\n",
    "        return\n",
    "\n",
    "    eeg_data = df.iloc[:, 1:9].values.T\n",
    "    window_samples = int(window_sec * SAMPLING_RATE)\n",
    "    step_samples = int(step_sec * SAMPLING_RATE)\n",
    "\n",
    "    times, pred_labels, confidences = [], [], []\n",
    "    music_playing = False\n",
    "    start = 0\n",
    "\n",
    "    while start + window_samples <= eeg_data.shape[1]:\n",
    "        end = start + window_samples\n",
    "        window = eeg_data[:, start:end]\n",
    "\n",
    "        features = extract_features_improved(window)\n",
    "        feature_vec = np.array(features).reshape(1, -1)\n",
    "\n",
    "        pred_num = demo_pipeline.predict(feature_vec)[0]\n",
    "        pred_proba = demo_pipeline.predict_proba(feature_vec)[0]\n",
    "        confidence = max(pred_proba)\n",
    "        label = demo_num_to_label[pred_num]\n",
    "\n",
    "        mid_time = (start + end) / 2 / SAMPLING_RATE\n",
    "        times.append(mid_time)\n",
    "        pred_labels.append(label)\n",
    "        confidences.append(confidence)\n",
    "\n",
    "        emoji = \"Relaxed    \" if label == \"relaxed\" else \"NOT RELAXED\"\n",
    "        conf_bar = \"#\" * int(confidence * 20) + \".\" * (20 - int(confidence * 20))\n",
    "        print(f\"  {mid_time:6.1f}s  {emoji}  [{conf_bar}] {confidence:.0%}\")\n",
    "\n",
    "        if label == 'not_relaxed' and not music_playing:\n",
    "            play_soothing_music()\n",
    "            music_playing = True\n",
    "            print(f\"           >>> Playing soothing music...\")\n",
    "        elif label == 'relaxed' and music_playing:\n",
    "            stop_soothing_music()\n",
    "            music_playing = False\n",
    "            print(f\"           >>> Music stopped - brain is relaxed!\")\n",
    "        start += step_samples\n",
    "\n",
    "    stop_soothing_music()\n",
    "\n",
    "    # Plot results\n",
    "    CLASS_COLORS = {'relaxed': '#2ecc71', 'not_relaxed': '#e74c3c'}\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), height_ratios=[3, 1])\n",
    "\n",
    "    for i, (t, label) in enumerate(zip(times, pred_labels)):\n",
    "        color = CLASS_COLORS[label]\n",
    "        ax1.axvspan(t - step_sec/2, t + step_sec/2, alpha=0.4, color=color)\n",
    "        ax1.plot(t, 1 if label == 'relaxed' else 0, 'o', color=color, markersize=10, zorder=5)\n",
    "\n",
    "    ax1.set_yticks([0, 1])\n",
    "    ax1.set_yticklabels(['Not Relaxed\\n(stressed/focused)', 'Relaxed\\n(calm/meditative)'], fontsize=13)\n",
    "    ax1.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax1.set_title('Brain State Over Time (with Auto-Soothing Music)', fontsize=16, fontweight='bold')\n",
    "    ax1.grid(True, axis='x', alpha=0.3)\n",
    "    patches = [mpatches.Patch(color='#2ecc71', label='Relaxed', alpha=0.6),\n",
    "               mpatches.Patch(color='#e74c3c', label='Not Relaxed (music plays)', alpha=0.6)]\n",
    "    ax1.legend(handles=patches, loc='upper right', fontsize=12)\n",
    "\n",
    "    ax2.fill_between(times, confidences, alpha=0.3, color='#3498db')\n",
    "    ax2.plot(times, confidences, color='#2980b9', linewidth=2)\n",
    "    ax2.set_ylabel('Model Confidence', fontsize=12)\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax2.set_ylim(0.4, 1.05)\n",
    "    ax2.axhline(y=0.7, color='orange', linestyle='--', alpha=0.5, label='70% threshold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(DATA_FOLDER, 'live_demo_result.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    relaxed_pct = sum(1 for l in pred_labels if l == 'relaxed') / len(pred_labels) * 100\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SESSION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Total time:         {times[-1]:.0f} seconds\")\n",
    "    print(f\"  Relaxed:            {relaxed_pct:.0f}% of session\")\n",
    "    print(f\"  Not relaxed:        {100-relaxed_pct:.0f}% of session\")\n",
    "    print(f\"  Average confidence: {np.mean(confidences):.0%}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "print(\"Demo function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f259d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE SIMULATED LIVE DEMO!\n",
    "\n",
    "test_file = os.path.join(DATA_FOLDER, 'test_subject.csv')\n",
    "\n",
    "if os.path.exists(test_file):\n",
    "    simulated_live_demo(test_file, window_sec=4, step_sec=2)\n",
    "else:\n",
    "    print(f\"Test file not found: test_subject.csv\")\n",
    "    print(f\"\\nRunning on a training file as demo instead:\")\n",
    "    for f in sorted(os.listdir(DATA_FOLDER)):\n",
    "        if f.endswith('.csv') and 'test' not in f.lower():\n",
    "            print(f\"   Using: {f}\")\n",
    "            simulated_live_demo(os.path.join(DATA_FOLDER, f), window_sec=4, step_sec=2)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2b536",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ…´ PART E: Real-Time Live Demo with OpenBCI Headset\n",
    "\n",
    "**The showstopper!** Connect your headset and classify brain state in real-time.\n",
    "\n",
    "### Setup checklist:\n",
    "1. OpenBCI headset is powered ON\n",
    "2. Bluetooth dongle is plugged into your laptop\n",
    "3. OpenBCI GUI is **CLOSED** (BrainFlow needs exclusive access)\n",
    "4. You know your serial port (see below)\n",
    "\n",
    "### Finding your serial port:\n",
    "- **Windows**: Device Manager -> Ports -> look for \"Silicon Labs\" -> e.g. `COM5`\n",
    "- **Mac**: Terminal -> `ls /dev/tty.*` -> look for `tty.usbserial-XXXXX`\n",
    "- **Linux**: Terminal -> `ls /dev/ttyUSB*` -> usually `/dev/ttyUSB0`\n",
    "\n",
    "### How it works:\n",
    "```\n",
    "OpenBCI Headset (on head)  ->  Bluetooth  ->  USB Dongle  ->  BrainFlow  ->  Our Model  ->  Music!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61046f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS TO YOUR PORT!\n",
    "SERIAL_PORT = 'COM5'    # Windows: 'COM5', Mac: '/dev/tty.usbserial-XXXXX', Linux: '/dev/ttyUSB0'\n",
    "print(f\"Serial port: {SERIAL_PORT}\")\n",
    "print(\"(Change in the cell above if needed!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainflow.board_shim import BoardShim, BrainFlowInputParams, BoardIds\n",
    "from brainflow.data_filter import DataFilter, FilterTypes\n",
    "\n",
    "def live_realtime_demo(port=SERIAL_PORT, window_sec=4, update_sec=1, duration_sec=120):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"REAL-TIME BRAIN STATE CLASSIFICATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Port: {port} | Window: {window_sec}s | Duration: {duration_sec}s\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    saved = joblib.load(MODEL_PATH)\n",
    "    rt_pipeline = saved['pipeline']\n",
    "    rt_num_to_label = saved['num_to_label']\n",
    "\n",
    "    params = BrainFlowInputParams()\n",
    "    params.serial_port = port\n",
    "    board = BoardShim(BoardIds.CYTON_BOARD.value, params)\n",
    "    sampling_rate = BoardShim.get_sampling_rate(BoardIds.CYTON_BOARD.value)\n",
    "    eeg_channels = BoardShim.get_eeg_channels(BoardIds.CYTON_BOARD.value)\n",
    "    window_samples = int(window_sec * sampling_rate)\n",
    "\n",
    "    print(f\"\\nConnecting to OpenBCI Cyton...\")\n",
    "\n",
    "    try:\n",
    "        board.prepare_session()\n",
    "        board.start_stream()\n",
    "        print(\"Connected! Streaming started!\")\n",
    "        print(f\"\\nBuffering data ({window_sec + 1} seconds)...\\n\")\n",
    "        time.sleep(window_sec + 1)\n",
    "\n",
    "        music_playing = False\n",
    "        start_time = time.time()\n",
    "        print(\"Classification started! (Ctrl+C to stop)\\n\")\n",
    "\n",
    "        while (time.time() - start_time) < duration_sec:\n",
    "            data = board.get_current_board_data(window_samples)\n",
    "            if data.shape[1] < window_samples:\n",
    "                time.sleep(0.5)\n",
    "                continue\n",
    "\n",
    "            eeg_window = data[eeg_channels, :]\n",
    "            for ch in range(eeg_window.shape[0]):\n",
    "                DataFilter.perform_bandpass(eeg_window[ch], sampling_rate, 1.0, 45.0, 4, FilterTypes.BUTTERWORTH.value, 0)\n",
    "                DataFilter.perform_bandstop(eeg_window[ch], sampling_rate, 58.0, 62.0, 4, FilterTypes.BUTTERWORTH.value, 0)\n",
    "\n",
    "            features = extract_features_improved(eeg_window)\n",
    "            feature_vec = np.array(features).reshape(1, -1)\n",
    "            pred_num = rt_pipeline.predict(feature_vec)[0]\n",
    "            pred_proba = rt_pipeline.predict_proba(feature_vec)[0]\n",
    "            confidence = max(pred_proba)\n",
    "            label = rt_num_to_label[pred_num]\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            tag = \"Relaxed    \" if label == \"relaxed\" else \"NOT RELAXED\"\n",
    "            conf_bar = \"#\" * int(confidence * 20) + \".\" * (20 - int(confidence * 20))\n",
    "            print(f\"  [{time.strftime('%H:%M:%S')}] {tag} [{conf_bar}] {confidence:.0%}  ({elapsed:.0f}s/{duration_sec}s)\")\n",
    "\n",
    "            if label == 'not_relaxed' and not music_playing:\n",
    "                play_soothing_music()\n",
    "                music_playing = True\n",
    "                print(\"           >>> Soothing music started...\")\n",
    "            elif label == 'relaxed' and music_playing:\n",
    "                stop_soothing_music()\n",
    "                music_playing = False\n",
    "                print(\"           >>> Music stopped - relaxed!\")\n",
    "            time.sleep(update_sec)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nDemo stopped by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nConnection error: {e}\")\n",
    "        print(f\"   1. Is port '{port}' correct?\")\n",
    "        print(f\"   2. Is headset powered ON?\")\n",
    "        print(f\"   3. Is Bluetooth dongle plugged in?\")\n",
    "        print(f\"   4. Is OpenBCI GUI CLOSED?\")\n",
    "    finally:\n",
    "        stop_soothing_music()\n",
    "        try:\n",
    "            board.stop_stream()\n",
    "            board.release_session()\n",
    "        except:\n",
    "            pass\n",
    "        print(\"\\nDisconnected safely. Demo complete!\")\n",
    "\n",
    "print(\"Real-time demo function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ec1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE REAL-TIME DEMO!\n",
    "# Uncomment the line below when your headset is connected:\n",
    "\n",
    "# live_realtime_demo(port=SERIAL_PORT, window_sec=4, update_sec=1, duration_sec=120)\n",
    "\n",
    "print(\"Uncomment the line above when your OpenBCI headset is connected!\")\n",
    "print()\n",
    "print(\"Demo script for the judges:\")\n",
    "print(\"   1. Have a volunteer put on the headset\")\n",
    "print(\"   2. Run the cell above\")\n",
    "print(\"   3. Ask them to CLOSE THEIR EYES and breathe slowly (30 sec)\")\n",
    "print(\"      -> Model should say 'Relaxed'\")\n",
    "print(\"   4. Ask them to COUNT BACKWARDS from 1000 by 7s (1000, 993, 986...)\")\n",
    "print(\"      -> Model should say 'NOT RELAXED'\")\n",
    "print(\"      -> Soothing music starts playing!\")\n",
    "print(\"   5. Ask them to RELAX again (close eyes, breathe)\")\n",
    "print(\"      -> Music fades out as they calm down!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c49550",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ…µ PART F: Preparing for Judge Questions\n",
    "\n",
    "Here are the most likely questions judges will ask, with answers you can give confidently.\n",
    "\n",
    "---\n",
    "\n",
    "### Q1: \"How does your model work?\"\n",
    "\n",
    "**Answer:** \"We place 8 electrodes on the scalp using an OpenBCI headset. These measure tiny electrical signals called brainwaves. We break these signals into 5 frequency bands using a technique called Power Spectral Density. We calculate what percentage of total brain power is in each band. When someone is relaxed, alpha waves (8-13 Hz) are strong. When stressed, beta waves (13-30 Hz) dominate. We feed these 44 numbers into a Random Forest classifier (200 decision trees voting together) and it predicts relaxed vs. not relaxed.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q2: \"Why was your first model so bad?\"\n",
    "\n",
    "**Answer:** \"Three reasons! First, inconsistent labels: 'relaxing' and 'relaxation' were treated as different classes. Second, 5 classes with only ~19 files was too few for ML. Third, each 60-second recording only gave us one training sample. We fixed all three: merged labels into 2 classes, and used sliding-window augmentation to get 50+ samples from each recording.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q3: \"What is a Random Forest?\"\n",
    "\n",
    "**Answer:** \"Imagine asking 200 people to vote on whether brain data shows relaxation or stress. Each person (decision tree) looks at slightly different features and might make small mistakes. But the majority vote of all 200 is usually right! That's a Random Forest â€” wisdom of the crowd for machine learning.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q4: \"What are alpha and beta waves?\"\n",
    "\n",
    "**Answer:** \"Alpha waves oscillate at 8-13 Hz and are strongest when you're calm with eyes closed. Beta waves are faster at 13-30 Hz and increase when thinking hard or stressed. The ratio between alpha and beta power is the single best indicator of relaxation â€” and it's our model's most important feature.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q5: \"What is cross-validation?\"\n",
    "\n",
    "**Answer:** \"It's like taking 5 practice tests instead of one. We split data into 5 parts, train on 4 and test on 1, rotating which part is the test. Every sample gets tested exactly once, giving us a reliable accuracy estimate instead of just one lucky or unlucky split.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q6: \"How does the music feature work?\"\n",
    "\n",
    "**Answer:** \"Every second, the model predicts relaxed or not. If not relaxed, it starts playing calming ambient music with healing frequencies (174, 285, 396 Hz) and a breathing rhythm. Once it detects relaxation, the music fades out. It's a real-time biofeedback loop â€” the brain responds to the music, and the model detects the change!\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q7: \"What could you improve?\"\n",
    "\n",
    "**Answer:** \"More training data (30+ minutes per class), trying deep learning models like convolutional neural networks, adding more brain states (drowsy, focused, creative), building a real-time visual dashboard, and letting users pick their own music.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q8: \"Is this clinically accurate?\"\n",
    "\n",
    "**Answer:** \"This is a prototype, not a medical device. Clinical EEG uses many more electrodes and hospital-grade equipment. But the underlying science is real â€” the relationship between alpha/beta waves and mental state is well-established in neuroscience. Consumer EEG devices are being used for meditation apps, ADHD treatment, and sleep monitoring.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q9: \"How much data did you need?\"\n",
    "\n",
    "**Answer:** \"We started with only 19 recordings (about 19 minutes total). Using sliding-window augmentation with a 4-second window and 1-second step, we turned those into over 1,000 training samples. More data always helps â€” we'd recommend 5+ minutes per recording and 10+ recordings per class.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Q10: \"What's the Welch method?\"\n",
    "\n",
    "**Answer:** \"It's a way to find which frequencies are strongest in a signal. It breaks the signal into small overlapping chunks, uses the Fourier Transform on each to find frequencies, then averages everything. The averaging reduces noise and gives a cleaner picture than a single Fourier Transform.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a20423",
   "metadata": {},
   "source": [
    "---\n",
    "## You're Ready for the Hackathon!\n",
    "\n",
    "### Demo flow for judges (10 minutes):\n",
    "1. **2 min** â€” Explain the concept (brain -> headset -> classifier -> music)\n",
    "2. **1 min** â€” Show the naive model failing (Part B)\n",
    "3. **2 min** â€” Show how you fixed it (Part C)\n",
    "4. **3 min** â€” Live demo with a volunteer (Part E)\n",
    "5. **2 min** â€” Answer questions (Part F)\n",
    "\n",
    "### Good luck! ðŸ§ ðŸ†\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
